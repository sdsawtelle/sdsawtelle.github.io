{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In which I learn how to cook word salad with a side of alphabet soup.\n",
    "\n",
    "Here I'll outline what exactly a regex *is*, the general anatomy of a regex and the specific python syntax for constructing them. I'm using the adorably tiny book [Regular Expression Pocket Reference](https://www.amazon.com/Regular-Expression-Pocket-Reference-Expressions/dp/0596514271) as well as the [official docs](https://docs.python.org/3.5/library/re.html#module-re) for the `re` module.\n",
    "\n",
    ">Tools covered:\n",
    "- constructing regex with proper syntax in python\n",
    "- searching, replacing and splitting by regexes using the `re` module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# General Principles of Regexes\n",
    "\n",
    "In his pocket reference Tony has done a great job condensing the essence of regex principles and syntax, so let me start by quoting him directly.\n",
    "\n",
    "> [Regexes] are a way to describe text through pattern matching... Regular expression syntax defines a language you use to describe text.\n",
    "\n",
    "In a regex the particular character pattern you are trying to match is described by some combination of normal characters, which mean exactly what they say (`a` means the letter \"a\"), and metacharacters and metasequences, which have special meaning like the quantity or location of characters. Sadly the particular syntax of a regex is specific to each programming language.\n",
    "\n",
    "You can picture a regex parser examining each character in the input string one-by-one sequentially, trying to fit it into the pattern described in your regex (a really neat discussion of the actual algorithmic behavior of regex engines is [here](http://stackoverflow.com/questions/3978438/dfa-vs-nfa-engines-what-is-the-difference-in-their-capabilities-and-limitations)). Tony identifies two main principles of regex operation that help you predict their behavior:\n",
    "\n",
    "1. **The leftmost match wins.** The parser will return you the first section of text it finds which completely matches your described pattern even if there might be another full match later on in the input string. \n",
    "2. **Most quantifiers are greedy**. If a part of your pattern describes an unspecified number of characters, the parser will keep matching input characters to it as long as possible. If the full pattern ultimately fails to be matched, only then will the parser try *backtracking* and giving up characters to the next part of the regex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Sets and Encodings\n",
    "\"Characters\" are not just standard printed symbols like letters, digits and punctation, but also things like newline and tab characters which create specific whitespace. There are even characters to control output \"devices\" in various ways, like an \"enquire\" character that requests a response from the device. **A common division is between \"printed\" and \"control\" characters, the former being all visual symbols, not including whitespace.** \n",
    "\n",
    "The smallest element of computer memory is a bit, which has two states $\\{0, 1\\}$, so that with a single bit you can only encode two different characters, say *a* and *b*. With two bits you have four possible states, $\\{00, 01, 10, 11\\}$ and so you can encode four different characters. Eight bits is called a *byte* and has 256 possible states.\n",
    "\n",
    "\n",
    "## Ascii \n",
    "This is a standard encoding for a specific set of characters that uses 1 byte per character. It specifies an encoding for 128 different printed and control characters (\"extended\" ASCII encodes an additional 128 characters). The letters in ASCII are only english. \n",
    "\n",
    "## Unicode \n",
    "This is a standard encoding that has a few variants like `utf-8`. For the characters in the ASCII char set, Unicode uses all the same binary encodings as ASCII, but it also augments this set by permitting more than 1 byte to be used for encoding and thus more total characters to be encoded. Unicode includes, for instance, letters from non-english languages.\n",
    "\n",
    "It's common to label and identify the specific characters of a char set not by our usual integers but instead in terms of base-8 (or base-16 for unicode) which is called \"octal\" (or \"hexadecimal\"). Note that this **standard numbering gives a natural ordering to the characters, which is useful in defining \"slices\" of a char set in regexes**, like *\"a through z\"*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anatomy of a Regex\n",
    "In his book Tony defines some really helpful categories of regex constructs that I'll repeat here with examples in Python regex syntax. Understanding the kinds of constructs that will show up should help us see the forest for the trees, so to speak.\n",
    "\n",
    "## Normal vs. Metacharacters\n",
    "First recall that within a regex there are normal characters, which mean exactly what they say (`a` means the letter \"a\"), and metacharacters, which have special meaning in the regex. In python the special metacharacters are:\n",
    "> . ^ $ * + ? { } [ ] \\ | ( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoting Single Characters\n",
    "There are several ways in which specific individual characters can be referred to within a regex. \n",
    "- Normal characters (not metacharacters) can just be written as-is like `a` means the letter \"a\".\n",
    "- Some control characters have special shorthand like `\\n` for newline.\n",
    "- Characters can be denoted by escaped octal numbers like `\\012` for newline.\n",
    "- Characters can be denoted by escaped and lettered hexadecimal numbers like `\\x0D` for a two-digit and `\\uFFFF` for a four-digit\n",
    "\n",
    "## Character Classes\n",
    "Classes are specific subsets of characters and a regex engine will try to match a single character of the input string to a character from the set. There is a variety of syntax for specifying different sets, and inside a class you can use the dash `-` to mean a slice. \n",
    "\n",
    "- `[ ]` matches any of the included characters like `[a-z]` means match any character in the set a through z (all the lowercase letters). \n",
    "- `[^ ]` matches the *complement* of the specified characters.\n",
    "- `.` matches every character except the newline\n",
    "- `\\d`, `\\w`, and `\\s` match all digits, word characters (alphanumerics plus underscore) and space characters, respectively. Using the uppercase like `\\D` means their complement. \n",
    "\n",
    "Inside the `[ ]` subset definition all the metacharacters are stripped of their meaning and revert being regular characters, except that special classes will still be recognized. Thus `[\\d$]` means the set including all digits and the dollars sign character, and `[.]` means match the actual period symbol (which is otherwise a metacharacter). \n",
    "\n",
    "## Anchors \n",
    "Anchor are metacharacters and metasequences that match a specific *position* in the input string rather than matching characters. They are also called \"zero-width assertions\" because they don't actually consume a character of the input string when they match.\n",
    "- `^` matches the start of the input string\n",
    "- `$` matches the end of the input string\n",
    "- `\\b` matches a \"word boundary\" which is a place where a word character (alphanumeric) is next to a non-word character (like punctuation). Using the uppercase `\\B` matches any place that's *not* a word boundary. \n",
    "\n",
    "Lookarounds are a different kind of zero-width assertion. They match *positions* where a specified sub-pattern *would* have matched, but they don't actually consume those characters that match the sub-pattern.\n",
    "\n",
    "- Lookahead matches locations where a subpattern is or is not matched in the **subsequent** text. Like `foo(?=bar)` matches all \"foo\"s followed by \"bar\"s, while `foo(?!bar)` matches all \"foo\"s *not* followed by \"bar\"s.\n",
    "- Lookbehind matches locations where a subpattern is or is not matched in the **preceeding** text. LIke `(?<=foo)bar` matches all \"bar\"s preceeded by \"foo\"s, while `(?&lt!foo)` bar matches all \"bar\"s *not* preeeded by \"foo\"s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Statements \n",
    "These are miscellaneous functionalities that are often handy.\n",
    "- `...|...` tries the two specfied subpatterns in alteration like `a|b` will first try to match \"a\" then if that fails try to match \"b\"\n",
    "- `( )` groups a subpattern so that the entire subpattern can be referrred to by a quantifier or alternator like `(a/d)|(b/d)` will first try to match \"a\" followed by digit and if that fails try \"b\" followed by a digit. \n",
    "\n",
    "Note that if you don't use grouping by `()` wih the alernator `|` then it tries to match *everything* to the left of the pipe and then *everything* to the right of the pipe. \n",
    "\n",
    "## Quantifiers\n",
    "Quantifiers control how many times the parser tries to match an element, and can be placed after single characters, character classes in brackets and subpatterns in parentheses. **Greedy quantifiers will match as many times as allowed while lazy quantifiers will match as few times as allowed.** \n",
    "\n",
    "- `*`, `+`, `?`, means greedily match at least 0 times, at least 1 time, and 0 or 1 times, respectively \n",
    "- `{x,y}` means greedily match at least x times but no more than y times like `a{3, 5}` means match the character \"a\" as many times as possible subject to the constraint of at least 3 but not more than 5 times.\n",
    "- `{n}` means match exactly n times\n",
    "\n",
    "Each greedy quantifier has a corresponding lazy quantifier whose syntax is identical just with an additional appended `?`, so for example `a+?` means match the character \"a\" as few times as possible subject to the constraint of at least one time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `re` Module for Python Regex\n",
    "The `re` module in the python standard library is where all of Python's regex functionality lives, the [official docs](https://docs.python.org/3.5/library/re.html) and this [simpler HOW TO](https://docs.python.org/3.5/howto/regex.html#regex-howto) are both great resources. \n",
    "\n",
    "In the `re` module you create a regex object from a pattern string by using the `compile()` function. The resulting object then has helper methods to do things like searching for matches or performing substitutions based on the pattern. \n",
    "\n",
    "It's important to write your regex pattern strings as python raw strings (`r\"\"` rather than `\"\"`) to avoid some craziness when it comes to backslash escaping. I'll just refer to this excellent [SO answer](http://stackoverflow.com/a/30164723)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern_str = r\"[bcf]at+y?\"  # see below for why the r-prefix\n",
    "regx= re.compile(pattern_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How will this regex match on \"ba\", \"bat\", \"catty\", \"fattyy\" or \"faaty\"? Let's break it down going from left to right through the regex pattern:\n",
    "1. insist on starting with a single \"b\", \"c\" or \"f\"\n",
    "2. insist on a single \"a\"\n",
    "3. insist on at least one \"t\", but as many as possible\n",
    "4. insist on 0 or 1 \"y\"s, but as few as possible\n",
    "\n",
    "So it won't match \"ba\" (no \"t\") or \"faaty\" (more than one \"a\"). From \"bat\" it returns \"bat\", from \"catty\" it returns \"catt\", and from \"fattyy\" it returns \"fatty\".\n",
    "\n",
    "### Look for a match with `search`\n",
    "This is how we actually use the regex pattern we compiled to check for matches against input strings. Remember, the regex will give us back the *leftmost* match and then stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search input string \"ba\" for a match to the regex - FAIL\n",
    "result = regx.search(\"ba\")\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_sre.SRE_Match"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search input string \"bat\" for a match to the regex - SUCCESS!\n",
    "result = regx.search(\"fattyy\")\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect matches as `match` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fatty'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at what text the resulting \"match\" contains\n",
    "result.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The start and stop positions of the match within the original input string\n",
    "result.span()  # \"fattyy[0:5] = \"fatty\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get text from subpattern groups\n",
    "You may think that `group` is a weird name for a method that shows you the text that matched the pattern. Actually in regexes each subpattern group in parentheses, `( )`, has it's match text internally captured and saved. If our regex has several subpattern groups defined in it then we can get all the resulting group strings with `groups`, while the whole matched string we get from `group`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('coolemail', 'hotdomain')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and search a regex that has subpattern groups defined\n",
    "regx_grp = re.compile(r\"(\\w*)@(\\w*)\\.[\\w]*\")  # has two defined groups\n",
    "result = regx_grp.search(\"coolemail@hotdomain.net\")\n",
    "\n",
    "\n",
    "# Get a tuple of the text for matched groups\n",
    "result.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coolemail@hotdomain.net'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the full matched text\n",
    "result.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ALL the matches!\n",
    "The `finditer()` method will return a generator that pops out a match object for each substring in the input string which matches the regex, while `findall()` just returns a list of the string matches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = regx.finditer(\"my fat cat was behaving in a very batty fashion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fat\n",
      "cat\n",
      "batty\n"
     ]
    }
   ],
   "source": [
    "for mtch in result:\n",
    "    print(mtch.group())  # print the matched substring for each match object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fat', 'cat', 'batty']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regx.findall(\"my fat cat was behaving in a very batty fashion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace substrings with other text\n",
    "You can replace occurrences of the pattern in the input string with new text of your choosing, and you can specify how many replacements will occur with kwarg `count` (they will always happen leftmost-first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my **CENSORED** **CENSORED** was behaving in a very batty fashion.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_str = \"my fat cat was behaving in a very batty fashion.\"\n",
    "regx.sub(repl=\"**CENSORED**\", string=inp_str, count=2)  # Only do the first two replacements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even pass it a function, to be run on each found match object, which will dictate the text that match is replaced by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my FAT CAT was behaving in a very BATTY fashion.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function which will uppercase the text of the match objects\n",
    "replace_with = lambda match: match.group().upper()\n",
    "\n",
    "regx.sub(repl=replace_with, string=inp_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split strings based on pattern matches\n",
    "At every occurrence of a match the matched text is removed from the input string and it is cleaved at that spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my ', ' ', ' was behaving in a very ', ' fashion.']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regx.split(string=inp_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile readable regexes in Verbose mode\n",
    "Regexes suck to try to read, the syntax is just too compact and confusing. If you want to write a regex that allows you to use liberal whitespace and even include comments then you can send the `re.Verbose` mode as an input to the compile function and using triple quotes to enclose your multi-line regex string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regx = re.compile(r\"\"\"\n",
    " [bcf]  # insist on starting with a single \"b\", \"c\" or \"f\"\n",
    " a      # insist on a single \"a\"\n",
    " t+     # insist on at least one \"t\", but as many as possible\n",
    " y?     # insist on 0 or 1 \"y\"s, but as many as possible\n",
    "\"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Problems\n",
    "\n",
    "### Email headers have the form *\"From hurst@missouri.co.jp  Fri Aug 23 11:03:04 2002\"*. Write a regex that only matches a string of this form, and has saved subpattern groups for the email address and time.  (Of course for such a rigid format `str.split()` would work just as well.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hurst@missouri.co.jp', '11:03:04')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_str = \"From hurst@missouri.co.jp Fri Aug 23 11:03:04 2002\"\n",
    "regx = re.compile(r\"^From\\s+(\\S*)\\s+\\w+\\s+\\w+\\s+\\d+\\s+([\\d:]*)\\s+\\d{4}\")\n",
    "\n",
    "regx.search(inp_str).groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace any sequence of whitespaces of any length with a single space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a crazily spaced sentence.'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_str = \"This    is a  crazily  spaced      sentence.\"\n",
    "regx = re.compile(r\"\\s+\")\n",
    "\n",
    "regx.sub(repl=\" \", string=inp_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [From [diveintopython](http://www.diveintopython3.net/regular-expressions.html)] You're working with addresses and you need to replace the word \"road\" (could be any case) with \"Rd.\" but only when it's at the end of the string (address). Hint: you can compile a case-insensitive regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'540 Hard Road Rd.'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_str1 = \"540 Hard Road Road\"\n",
    "inp_str2 = \"78 RIVER ROAD\"\n",
    "\n",
    "regx = re.compile(r\"road$\", re.IGNORECASE)\n",
    "regx.sub(repl=\"Rd.\",string=inp_str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'78 RIVER Rd.'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regx.sub(repl=\"Rd.\",string=inp_str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [From [diveintopython](http://www.diveintopython3.net/regular-expressions.html)] You need to parse phone numbers to get the area code, local code, and last four digits. The phone numbers could come in any of the following forms:\n",
    "- 800-555-1212\n",
    "- 800 555 1212\n",
    "- 800.555.1212\n",
    "- (800) 555-1212\n",
    "- 1-800-555-1212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('800', '555', '1212')"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_str1 = \"800-555-1212\"\n",
    "inp_str2 = \"800.555.1212\"\n",
    "inp_str3 = \"(800) 555-1212\"\n",
    "inp_str4 = \"1-800-555-1212\"\n",
    "regx = re.compile(r\".*(\\d{3})[^\\w]{1,2}(\\d{3})[^\\w]{1,2}(\\d{4})\")\n",
    "\n",
    "regx.search(inp_str3).groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Censor every occurrence of a number in a medical statement like *\"The patient, aged 62, has BP measuring 130.6 over 25.\"* Use your favorite censorship stand-in. Careful of floats with decimal points!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The patient, aged **CENSORED**, has BP measuring **CENSORED** over **CENSORED**.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_str = \"The patient, aged 62, has BP measuring 130.6 over 25.\"\n",
    "regx = re.compile(r\"\\b\\d+[.]*\\d*\\b\")\n",
    "\n",
    "\n",
    "regx.sub(repl=\"**CENSORED**\", string=inp_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now instead replace every occurrence of an *integer* with its binary equivalent  - your regex should not match floats! Hint: `bin()` gives a text representation of the binary equivalent of a base-10 integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The patient, aged 0b111110, presented with blood pressure measuring 130.6 over 0b11001.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_str = \"The patient, aged 62, presented with blood pressure measuring 130.6 over 25.\"\n",
    "regx = re.compile(r\"\\b(?<!\\d[.])\\d+(?![.]\\d)\\b\")\n",
    "\n",
    "def replace_with(match):\n",
    "    txt = match.group()\n",
    "    return bin(int(txt))\n",
    "\n",
    "regx.sub(repl=replace_with, string=inp_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [From the official docs]. Find and print all adverbs in a sentence - you can assume they will all end with \"ly\". Hint: make sure your code can handle adverbs immediately followed by punctuation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carefully', 'quickly']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_str = \"He was carefully disguised but captured quickly by police.\"\n",
    "regx = re.compile(r\"\\b\\w+ly\\b\")\n",
    "\n",
    "regx.findall(inp_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [From the HOWTO]. Match all filenames whose extension is not *\".bat\"* and capture the filename and extension as two subpattern groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('myfile', 'bmp')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_str1 = \"myfile.bmp\"\n",
    "inp_str2 = \"myfile2.bat\"\n",
    "\n",
    "regx = re.compile(r\"(.+)[.](?!bat)(.+)\") # Use a negative look ahead\n",
    "regx.search(inp_str1).groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(regx.search(inp_str2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up a sentence by every occurrence of punctuation in it. Hint: punctuation is not a letter, digit, or whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They say ', 'stop', ' in the name of love', ' I quite agree', '']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_str = \"They say 'stop, in the name of love'. I quite agree!\"\n",
    "\n",
    "regx = re.compile(r\"[^\\w\\d\\s]+\")\n",
    "regx.split(string=inp_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match the interior content of all the html tags in the string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is a pic', 'this is a div']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_str = \"&lt img src=test.png>this is a pic</img> &lt div>this is a div</div>\"\n",
    "regx = re.compile(r\"(?<=>)([^<>]*)(?=</)\")  # yeah this breaks for content with greater/less than\n",
    "regx.findall(inp_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Resources\n",
    "- A [very thorough guide](http://www.regular-expressions.info/alternation.html) to regex constructs and syntax\n",
    "- An [intro with lots of great examples](http://www.diveintopython3.net/regular-expressions.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
