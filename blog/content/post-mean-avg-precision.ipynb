{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In which I spare you an abundance of \"map\"-related puns while explaining what Mean Average Precision is. \n",
    "\n",
    "(Ok there's one pun.) Since you're reading this I'm assuming you've come up against the slightly convoluted \"Mean Average Precision\", or MAP metric for evaluating ML algorithms. If you are here on a kaggle quest then you are me two days ago - kaggle is where I first heard about MAP and the reason I typed up this post. \n",
    "\n",
    "MAP is very popular evaluation metric for algorithms that do information retrieval (think google search results) but it also can apply to user-targeted product recommendations. **If you have an algorithm that is returning a ranked ordering of items, each item is either hit or miss (imagine relevant vs. irrelevant search results) and items further down in the list are less likely to be used/seen (imagine search results at the bottom of the page), then maybe MAP is the metric for you!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP for Recommender Algorithms\n",
    "MAP is a pretty common metric for user recommendation systems, like when Amazon shows you a short list of products it thinks you might *also* want to purchase after you've added something to your cart. **Using MAP to evaluate a recommender algorithm implies that you are treating the recommendation like a ranking task.** This often makes perfect sense! A user has a finite amount of time and attention, so we want to know not just five products they might like, but also which are most liked or which we are most confident of. This lets you show the top recommendations first and maybe market them more aggressively.\n",
    "\n",
    "So we just want a metric that rewards you for getting lots of \"correct\" or relevant recommendations, and rewards you for having them earlier on in the list (higher ranked). Before we can construct this metric though, we need **Precision** and **Recall**. That's what I call my left and right fist. Only joking, those are actually two things I conveniently just learned about in Andrew Ng's ML course on Coursera!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall of a Binary Classifier\n",
    "So let's start where professor Ng started. If we have binary classifier for predicting having a condition ($y=1$) vs not, then we define:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\textrm{precision:} \\qquad P = \\frac{\\textrm{# correct positive}}{\\textrm{# predicted positive}}\\\\\n",
    "\\\\\n",
    "\\textrm{recall:} \\qquad r  = \\frac{\\textrm{# correct positive}}{\\textrm{# with condition}}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "In maybe more familiar terminology, precision is (1 -  *false positive rate*), and the recall is (1 - *false negative rate*). Actually I'm baffled as to why two new terms were needed for this. \n",
    "\n",
    "It might also be helpful to some people to think in terms of conditional probabilities: $P = \\textrm{P}(y=1\\  \\big|\\  h_\\theta(x)=1)$ and $r =  \\textrm{P}(h_\\theta(x)=1 \\ \\big| \\  y=1)$, where $h_\\theta(x)$ is the prediction output of your algorithm for data point $x$. (IF THAT WAS CONFUSING JUST PRETEND YOU DIDN'T HEAR IT.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall of Recommender Systems\n",
    "OK so how does this map (ding!) to recommender systems? In modeling pretty much all recommendation systems we're going to have the following quantities with their corresponding ones in the binary classifier:\n",
    "\n",
    "|  Terminology in Binary Classifier  |  Terminology in Recommender System  |\n",
    "|------|------|\n",
    "| # with condition |  the number of all the actually relevant (\"correct\") items for a user| \n",
    "| # predicted positive | the number of items we selected to recommend to a user (we predicted these as \"relevant\")   |\n",
    "| # correct positives | the number of items that are actually relevant from among those that we selected to recommend |\n",
    "\n",
    "OK so now with almost no effort we have:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\textrm{recommender system precision:} \\qquad P = \\frac{\\textrm{# of our recommendations that are relevant}}{\\textrm{# of items we recommended}}\\\\\n",
    "\\\\\n",
    "\\textrm{recommender system recall:} \\qquad r  = \\frac{\\textrm{# of our recommendations that are relevant}}{\\textrm{# of all the possible relevant items}}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Let's say I am asked to recommend $N=5$ products (this means I predict \"positve\" for five prducts), from all the possible products there are only $m=3$ that are actually relevant to the user, and my successes and failures in my ranked list are $[0, 1, 1, 0, 0]$. Then:\n",
    "- \\# of items we recommended = 5\n",
    "- \\# of our recommendations that are relevant = 2\n",
    "- \\# of all the possible relevant items = 3\n",
    "- precision = 2/5\n",
    "- recall = 2/3\n",
    "\n",
    "\n",
    "People love examples, so here's a visual one. Let's say we're being asked to recommend financial \"products\" to Bank users and we compare our recommendations to the products that a user actually added in the following month (these are all the possible \"relevant\" ones).\n",
    "\n",
    "<img src=\"images/map/area_pic.png\" width=800></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall at Cutoff k\n",
    "So that's nice and all, BUT Precision and Recall don't give a crap about ordering of our recommendations. So instead let's talk about **precision and recall at cutoff k**. Imagine taking your list of $N$ recommendations and considering only the first element, then only the first two, then only the first three, etc... these subsets can be indexed by $k$. **Precision at cutoff k, $P(k)$, and Recall at cutoff k, $r(k)$, are simply the precision and recall calculated by considering only the subset of your recommendations from rank 1 through $k$**. Really it would be more intuitive to say \"up to cutoff k\" rather than \"at\".\n",
    "\n",
    "Sticking with the bank example, here is what I mean:\n",
    "<img src=\"images/map/subset_pic.png\" width=800></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Precision\n",
    "OK are you ready for Average Precision now? If we are asked to recommend $N$ items, the number of relevant items in the full space of items is $m$, then:\n",
    "\n",
    "\\begin{align*}\n",
    "\\textrm{AP@N} = \\frac{1}{m}\\sum_{k=1}^N \\textrm{($P(k)$ if $k^{th}$ item was relevant)} = \\frac{1}{m}\\sum_{k=1}^N P(k)\\cdot rel(k),\n",
    "\\end{align*}\n",
    "\n",
    "where $rel(k)$ is just an indicator that says whether that $k^{th}$ item was relevant ($rel(k)=1$) or not ($rel(k)=0$). I'd like to point out that instead of recommending $N$ items would could have recommended, say, $2N$, but the AP@N metric says we only care about the average precision up to the $N^{th}$ item. \n",
    "\n",
    "# Examples and Intuition for AP\n",
    "Let's imagine recommending $N=3$ products (AP@3) to a user who actually added a total of $m=3$ products. Here are some examples of outcomes:\n",
    "\n",
    "|  ________Recommendations________ |  ________Precision @k's________  | ________AP@3________ |\n",
    "|----------------------|----------------------|----------------------|\n",
    "|  [1, 0, 0]  |  [1/1, 1/2, 1/3]  |   (1/3)(1) = 1/3  |\n",
    "|  [0, 1, 0]  |  [0, 1/2, 1/3]  |  (1/3)(1/2) = 1/6|\n",
    "|  [0, 0, 1]  |  [0, 0, 1/3]  |  (1/3)(1/3) = 1/9 |\n",
    "\n",
    "Notice that in all the rows you got just one recommendations correct, but when it was your first recommendation you got the largest AP. Having your one correct recommendation as the second element was half as good as having it as the first and one third as good when you instead have it as the third element. How about some more examples to illustrate this subtlety.\n",
    "\n",
    "|  ________Recommendations________|  ________Precision @k's________  | ________AP@3________  |\n",
    "|------|------||------|------||------|\n",
    "|  [0, 0, 1]  |  [0, 0, 1/3]  |  (1/3)**(1/3)** = 1/9  |\n",
    "|  [0, 1, 1]  |  [0, 1/2, 2/3]  |  (1/3)[(1/2) + **(2/3)**] = 7/18  |\n",
    "|  [1, 1, 1]  |  [1/1, 2/2, 3/3]   |  (1/3)[(1) + (2/2) + **(3/3)**] = 1 |\n",
    "\n",
    "Notice that starting from the first row where only the third recommendation is correct, when I add in a second and third correct element I get an increasing AP. This is because the $k^{th}$ subset precision is included in AP sum only if you got the $k^{th}$ recommendation correct, thus **AP rewards you for giving correct recommendations** (surprising absolutely no one). \n",
    "\n",
    "Now the third row of the table - here we're getting everything right so each element is adding the same $P(k)=1$ to the precision. Now look at the last column of the table, in each row I've bolded the term which came from the correct recommendation in the third slot. Notice it is bigger when there have been more successes in front of it - that's because your precision for the $k^{th}$ subset is larger the better you've done up to $k$. Thus, **AP rewards you for front-loading the recommendations that are most likely to be correct**. \n",
    "\n",
    "These two features are what makes AP a useful metric when your algorithm is returning a ranked ordering of items, each item is either hit or miss, and items further down in the list are less likely to be used/seen. A final point of note is that adding another recommendation can never *decrease* your AP score, so if you are asked for $N$ recommendations give all of them, even if you don't feel very confident about the ones lower down the list! **AP will never penalize you for tacking on additional recommendations to your list - just make sure you front-load the best ones.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The \"Mean\" in MAP\n",
    "OK that was Average Precision, which applies to a single data point (like a single user). What about MAP@N? All that remains is to average the AP@N metric over all your $|U|$ users. Yes, an average of an average.\n",
    "\n",
    "\\begin{align*}\n",
    "\\textrm{MAP@N} = \\frac{1}{|U|}\\sum_{u=1}^|U|(\\textrm{AP@N})_u = \\frac{1}{|U|} \\sum_{u=1}^|U| \\frac{1}{m}\\sum_{k=1}^N P_u(k)\\cdot rel_u(k).\n",
    "\\end{align*}\n",
    "\n",
    "## Minor Details\n",
    "Often you see the AP metric modified slightly when there might be more possible correct recommendations then the number of recommendations you are asked to give. Say, a super active user at the bank who adds $m=10$ accounts the next month, while your algorithm is only supposed to report $N=5$. In this case the normalization factor used is $1/\\textrm{min}(m, N)$, which prevents your AP score from being unfairly suppressed when your number of recommendations couldn't possibly capture all the correct ones. \n",
    "\n",
    "\\begin{align*}\n",
    "\\textrm{AP@N} = \\frac{1}{\\textrm{min}(m,N)}\\sum_{k=1}^N P(k)\\cdot rel(k).\n",
    "\\end{align*}\n",
    "\n",
    "You also might encounter a somewhat sloppier usage where there is no indicator function $rel(k)$ in the AP@N sum. In this case the person is re-defining the precision at cutoff $k$ to be zero when the $k^{th}$ recommendation was incorrect, that way it still doesn't contribute to the sum:\n",
    "\n",
    "\\begin{align*}\n",
    "\\textrm{AP@N} = \\frac{1}{m}\\sum_{k=1}^N P(k),\\\\\n",
    "P(k) = 0 \\textrm{ if $k^{th}$ element is irrelevant / incorrect.}\n",
    "\\end{align*}\n",
    "\n",
    "Finally, the if it's possible for there to be no relevant or correct recommendations possible ($m=0$) then often the AP is defined to be zero for those points. This is just to prevent us from trying to divide by zero in the normalization. Note that it will have the effect of dragging the MAP number of an algorithm down the more users there are who didn't actually add any products. This doesn't matter for comparing the performance of two algorithms on the same data set, but it does mean that you shouldn't place any kind of absolute meaning on the final number.\n",
    "\n",
    "\\begin{align*}\n",
    "\\textrm{AP@N} = \\frac{1}{\\textrm{min}(m,N)}\\sum_{k=1}^N P(k)\\cdot rel(k) \\qquad \\textrm{ if $m\\neq 0$,}\\\\\n",
    "AP = 0 \\qquad \\textrm{if $m=0$}.\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So Why Did I Bother Defining Recall?\n",
    "There is an alternative formulation for the AP in terms of Precision *and* Recall, and I didn't want you to feel left out when people start talking about it at parties:\n",
    "\n",
    "\\begin{align*}\n",
    "\\textrm{AP@N} = \\sum_{k=1}^N \\textrm{(precision at $k$)}\\cdot\\textrm{(change in recall at $k$)} = \\sum_{k=1}^N P(k)\\Delta r(k),\n",
    "\\end{align*}\n",
    "\n",
    "where $\\Delta r(k)$ is the change in recall from the $k-1^{th}$ to the $k^{th}$ subset. This formulation is actually kind of nice because we don't need to \"leave out\" terms in the sum with an indicator function, instead the change in recall term is zero when the $k^{th}$ recommendation is incorrect so those guys get wiped out anyway. Hopefully you noticed that the prefactor $1/m$ is missing too, it turns out that when the $k^{th}$ recommendation *is* correct the change in recall is exactly $1/m$.  OK let me stop talking and make with the examples. Same as before, recommending $N=3$ products (AP@3) to a user who actually added a total of $m=3$ products:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  ________Recs________  |  ________Prec @k's________ |  ________Recall @k's________  |  ________Change r @k's________  |  ________AP@3________  |\n",
    "|------|------|\n",
    "|  [1, 0, 0]  |  [1, 1/2, 1/3]  | [1/3, 1/3, 1/3]  |  [1/3, 0, 0]  |  (1)(1/3) = 1/3 |\n",
    "|  [0, 1, 0]  |  [0, 1/2, 1/3]  | [0, 1/3, 1/3]  |  [0, 1/3, 0]  |  (1/2)(1/3) = 1/6|\n",
    "|  [0, 0, 1]  |  [0, 0, 1/3]  | [0, 0, 1/3]  |  [0, 0, 1/3]  |  (1/3)(1/3) = 1/9 |\n",
    "\n",
    "\n",
    "|  ________Recs________  |  ________Prec @k's________ |  ________Recall @k's________  |  ________Change r @k's________  |  ________AP@3________  |\n",
    "|------|------|\n",
    "|  [0, 0, 1]  |  [0, 0, 1/3]  | [0, 0, 1/3]  |  [0, 0, 1/3]  |  **(1/3)(1/3)** = 1/12  |\n",
    "|  [0, 1, 1]  |  [0, 1/2, 2/3]  | [0, 1/3, 2/3]  |  [0, 1/3, 1/3]  |  (1/3)(1/2) + **(1/3)(2/3)** = 7/18  |\n",
    "|  [1, 1, 1]  |  [1, 2/2, 3/3]  | [1/3, 2/3, 3/3]  |  [1/3, 1/3, 1/3]  |  (1/3)(1) + (1/3)(1) + **(1/3)(1)** = 3/4 |\n",
    "\n",
    "Hopefully you can convince yourself that you are getting exactly the same result for this formulation of AP as we got before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical Representation of $P(i)$ and $r(i)$\n",
    "We can think of $P(i)$ and $r(i)$ as functions of the index $i$, and we can plot them accordingly, e.g. $P(i)$ vs. $i$. The resulting plot would of course depend heavily on the particular sequence of correct/incorrect recommendations that we are indexing through. More often what you see is a plot in the $P(i)$ x $r(i)$ plane that traces out the trajectory of both these quantities as you index through the list of recommendations. Analytically we can already imagine what such a trajectory will do: if at the next $i$ we got a correct recommendation then both precision and recall should increase, whereas if we got that recommendation wrong then precision will decrease while recall will be unchanged. \n",
    "\n",
    "Let me show you :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.5, 0.3333333333333333, 0.5, 0.4, 0.5, 0.5714285714285714]\n",
      "[0.0, 0.2, 0.2, 0.4, 0.4, 0.6, 0.8]\n"
     ]
    }
   ],
   "source": [
    "recoms = [0, 1, 0, 1, 0, 1, 1]  # N = 7\n",
    "NUM_ACTUAL_ADDED_ACCT = 5 \n",
    "precs = []\n",
    "recalls = []\n",
    "\n",
    "for indx, rec in enumerate(recoms):\n",
    "    precs.append(sum(recoms[:indx+1])/(indx+1))\n",
    "    recalls.append(sum(recoms[:indx+1])/NUM_ACTUAL_ADDED_ACCT)\n",
    "\n",
    "print(precs)\n",
    "print(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x245c3b25fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEbCAYAAADAsRPLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x245c36274e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recalls, precs, markersize=10, marker=\"o\")\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "ax.set_title(\"P(i) vs. r(i) for Increasing $i$ for AP@7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jaggedness of this type of plot has lead to the creation of some \"smoothed\" average precision metrics as alternatives, but I'll not talk about them here. \n",
    "\n",
    "# To Summarize...\n",
    "MAP is very popular evaluation metric for algorithms that do information retrieval (think google search results) but it also can apply to user-targeted product recommendations. If you have an algorithm that is returning a ranked ordering of items, each item is either hit or miss (imagine relevant vs. irrelevant search results) and items further down in the list are less likely to be used/seen (imagine search results at the bottom of the page), then MAP might be a useful metric. Using MAP to evaluate a recommender algorithm implies that you are treating the recommendation like a ranking task. This often makes perfect sense since a user has a finite amount of time and attention and we want to show the top recommendations first and maybe market them more aggressively. \n",
    "\n",
    "In recommendation systems MAP computes the mean of the Average Precision (AP) over all your users. The Average Precision is a measure that takes in a ranked list of your $N$ recommendations and compares it to a list of the true set of relevant recommendations for that user. AP rewards you for having a lot of \"correct\" (relevant) recommendations in your list, and rewards you for putting the most likely correct recommendations at the top (you are penalized more when incorrect guesses are higher up in the ranking). So order of \"hits\" and \"misses\" matters a lot in computing an AP score, but once you have front-loaded your best guesses you can never *decrease* your AP by tacking on more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Reading on MAP\n",
    "- from the source itself... [wikipedia](https://en.wikipedia.org/wiki/Information_retrieval#Average_precision)\n",
    "- from an all-things-ML blog [fast ML](http://fastml.com/what-you-wanted-to-know-about-mean-average-precision/)\n",
    "- from [Stanford class slides](http://web.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf) \n",
    "- from a [DS blog](https://sanchom.wordpress.com/tag/average-precision/)\n",
    "- from a [Stanford online book](http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval-results-1.html)\n",
    "- from June Andrews on why [MAP is \"mean\"](https://juneandrews.com/2014/12/15/mean-average-precision-isnt-so-nice/)\n",
    "- from [Cornell class slides](http://www.cs.cornell.edu/courses/cs4300/2013fa/lectures/metrics-2-4pp.pdf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
